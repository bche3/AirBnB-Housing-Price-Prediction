---
title: "AirBNB L.A. Price Prediction"
subtitle: "UCSB PSTAT 131 Final Project"
author: "Brian Che"
date: "Fall 2022"
output:
  html_document:
    code_folding: show
    toc: true
    toc_float: true
    theme: united
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

![](images/AirBNB_logo.png){width="25%"} ![](images/AirBNB_LA.jpg){width="44%"}

## Introduction

This machine learning project consists of building 4 different predictive models to find the best predictor of AirBnB Los Angeles listing prices through regression.

### What is AirBnB?

AirBnB, standing for "Air Bed and Breakfest" is a vacational rental company that serves as an online marketplace that connects people who want to rent out their homes with people who are looking for accomodations at their preferred destinations. Travelers are able to rent a space for multiple people to share, a shared space with private rooms, or the entire property for themselves for a specific duration of days. Essentially, each listing is set at minimum price per night by the owner for their property that is caclulated into the toal pricing of their stay, which may usually include service fees, tax, etc.

### Overview of the Dataset

The dataset I'll be using is from "[Inside AirBnB](http://insideairbnb.com/get-the-data/)" which is a mission driven project that provides data and advocacy about Airbnb's impact on residential communities, and is specifically focused on the Los Angeles, California, U.S. region at a compile date of September 9, 2022. The dataset consists of 45,815 rows (listings) and 18 predictors that serve as the listing background information.

### Our Focus

With new hosts wanting to add their property for rent on the platform, a competitive and reasonable price charged per night must be established for success in renting and appealing to consumers. While this will obviously vary through factors such as market value price, the neighborhood area, or simply being within an attraction or tourist hot spot, we can use machine learning to simplify this process of predicting housing prices to utilize, using this vast dataset with thousands of previously established listings.

### Load libraries and data

We first load the libraries we will be using and reading in the data, taking a look at the 18 variables.

```{r,warning=FALSE,message=FALSE, class.source = 'fold-hide'}
# load libraries
library(tidyverse)
library(tidymodels)
library(ggplot2)
library(yardstick)
library(corrplot)
library(randomForest)
library(xgboost)
library(vip)
library(rpart.plot)
library(ranger)
library(kernlab)
library(kknn)
library(baguette)

# read in data (45)
airbnb <- read_csv("data/unprocessed/listings.csv")
```

## Exploratory Data Analysis

By performing EDA, we can get a better understanding of the data and ultimately help us determine the predictors that we will be including within our recipe for our response variable `price`. Specifically, I will be taking a look at the relationships price may have with the other variables. Throughout this process, I will also be cleaning the data to prevent errors that may be occurring as we run our code analysis.

### Data Cleaning

```{r}
airbnb %>% glimpse()
```

From a general outlook, we can see that there are 11 numeric variables and 7 non-numeric variables of data type `chr`, which will help us condense our dataset into the variables we'll be prioritizing from ones that may be more irrelevant.

```{r, class.source = 'fold-hide'}
sapply(airbnb, function(x) sum(is.na(x)))
```

The variables with missing values that stick out to us are `neighbourhood_group` and `reviews_per_month`, which we'll need to manipulate the data to resolve. `neighbourhood_group` will be an important predictor that is required for every listing and should not be missing. For `reviews_per_month`, there is an issue for listings with 0 reviews at all to show NA, so we'll replace the NA values with 0. `Price` and `Availability_365` can't have a value of 0 as that would be mean it would never be available so we remove rows with this value. Lastly, we remove `id`, `name`, `host_id`, `host_name`, `last_review`, and `license`.

```{r}
airbnb$reviews_per_month[is.na(airbnb$reviews_per_month)] <- 0

airbnb$neighbourhood_group <- factor(airbnb$neighbourhood_group, levels = c('City of Los Angeles', 'Other Cities', 'Unincorporated Areas'))

airbnb$room_type <- factor(airbnb$room_type, levels = c('Entire home/apt', 'Hotel room', 'Private room', 'Shared room'))

airbnb <- airbnb %>%
  rename(host_listings_count = calculated_host_listings_count) %>%
  # remove the 14 rows with price equal to 0 because a listing price of 0 can't be possible
  filter(price != 0) %>%
  filter(availability_365 != 0) %>%
  filter(!is.na(neighbourhood_group)) %>%
  select(-id, -name, -host_id, -host_name, -last_review, -license)

set.seed(2022)
airbnb <- airbnb[sample(nrow(airbnb), size=15000), ]
```

```{r, class.source = 'fold-hide'}
# sanity check
airbnb %>%
  summary()
```

For sake of faster runtime, we will subset the dataset to a random sample of 15,000, and as a sanity check, we take a look at the summary for the numeric statistics and presence of missing values, we can see all conflict was resolved through our data cleaning.

```{r, class.source = 'fold-hide'}
# include use="pairwise.complete.obs" to exclude NAs
corrplot(cor(Filter(is.numeric, airbnb)), method = 'color', )
```

Using a correlation plot on the continuous variables, we observe that `number_of_reviews_ltm` and `reviews_per_month` for being highly correlated with `number_of_reviews`, and we pay close to attention to other variables relation with `price` to find nothing overwhelmingly significant yet asides from a slight negative correlation with the latter variables.

```{r}
# drop number_of_reviews_ltm and reviews_per_month for being highly correlated with number_of_reviews
airbnb_clean <- airbnb %>%
  select(-neighbourhood, -number_of_reviews_ltm, -reviews_per_month)
```

```{r,  warning=FALSE, message=FALSE, class.source = 'fold-hide'}
write_rds(airbnb_clean, "data/processed/airbnb_clean.rds")
```

```{r, warning=FALSE}
ggplot(airbnb_clean, aes(price)) +
  geom_histogram(bins = 30, aes(y = ..density..), fill = "purple") + 
  geom_density(alpha = 0.2, fill = "purple") +
  ggtitle("Distribution of Price") +
  theme(axis.title = element_text(), axis.title.x = element_text()) +
  geom_vline(xintercept = round(mean(airbnb$price), 2), size = 2, linetype = 3)
```

```{r, class.source = 'fold-hide'}
NAnalysis <- airbnb_clean %>% 
  group_by(neighbourhood_group) %>% summarise(Mean_Price = mean(price))

ggplot(NAnalysis, aes(x = reorder(neighbourhood_group, -Mean_Price), y = Mean_Price, fill=neighbourhood_group)) + 
  geom_bar(stat="identity", show.legend = FALSE) + 
  labs(title="Average Price of Rooms in each Neighbourhood Group") + 
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5), legend.position = c(0.8, 0.5)) + xlab("") + ylab("Mean Price")
```

We create a bar graph for the mean price by neighbourood groups with results of not too great of variation and the City of Los Angeles having the highest mean prices.

```{r, class.source = 'fold-hide'}
ggplot(airbnb_clean, aes(x = room_type, y = price)) +
  geom_boxplot(aes(fill = room_type)) + scale_y_log10() +
  xlab("Room Type") + 
  ylab("Price") +
  ggtitle("Housing Price by Room Type") +
  geom_hline(yintercept = mean(airbnb$price), color = "purple", linetype = 2)
```

Using a bar plot, we see that room_type, a categorical value, shows significant variation with its particular relationship to price with "Entire home/apt" having the highest mean price range with a mean around \$250, followed by hotel room with \$100, private room with \$85, and shared room with \$50. The variable `room_type` may show promise in its relationship with our response variable, which we'll include in our recipe through dummy variables.

## Data Splitting & Cross-validation

With our subsetted data we perform a log transformation on price due to its skewed distribution and use 80/20 split for training and testing. We aim to have a significant amount of data to train our models on, resultling with 11999 observations in our training set and 3001 observations in our testing set.

```{r}
set.seed(2022)
airbnb_split <- airbnb_clean %>% 
  mutate(price = log(price)) %>%
  initial_split(strata = price, prop = 0.8) 

airbnb_train <- training(airbnb_split)
airbnb_test <- testing(airbnb_split)

dim(airbnb_train)
dim(airbnb_test)
```



### Cross Validation Folding on Training

Using function `vfold_cv()`, we'll use stratified cross validation of 10 folds with strata `price` and overallow allows us to use it as a tool for machine learning by training a number of models on different subsets of the input data.

```{r, warning=FALSE,message=FALSE}
set.seed(2022)
airbnb_fold <- vfold_cv(airbnb_train, v = 10, strata = price)
```

## Model Fitting

As the main part of our project, we will be building four machine learning models that will utilize our formula `airbnb_recipe` to observe the results of different models trained on the same dataset and see which will provide the best accuracy in prediction. Our metrics that we will use to determine their performances will be the test R-squared and RMSE. Essentially, we will follow a similar process throughout all 4 model building processes, which is establishing the workflow with the model and parameters specified, use a tuning grid over the folds that will be resampled, select the best tuned model from the tuning, and create a final workflow that is then fit to our testing set. The four models we will be using are boosting, random forest, K-nearest neighbors, and bagging.


### Recipe Building

From our training dataset, we'll establish our recipe with `price` as a response variable with 8 predictors, using `step_dummy()` for our non-numeric predictors `room_type` and `neighbourhood_group`.

```{r, warning=FALSE,message=FALSE}
airbnb_recipe <- recipe(price ~ . , data = airbnb_train) %>%
  # dummy predictors for categorical values room_type and neighbourhood_group
  step_dummy(all_nominal_predictors()) 
```

### Boosting model

For the boosted model, the parameters used include a `tree_depth` of 8 for the number of maximum depth of the tree, ``levels` values of 10, and `trees` range from 10 to 500 as I found when adjusting the parameters for better accuracy around 500 as the accuracy decreased as the range end value did
```{r, warning=FALSE, message=FALSE, eval=FALSE}
set.seed(2022)

# trees = tune(), tree_depth = 8
boost_spec <- boost_tree(trees = tune(), 
                         tree_depth = 8) %>%
  set_engine("xgboost") %>%
  set_mode("regression")

# creating grid
boost_grid = grid_regular(trees(range = c(10, 500)), levels = 10)

# boosting workflow
boost_wf = workflow() %>%
  add_model(boost_spec) %>%
  add_recipe(airbnb_recipe)

# tuning grid for boosting model
boost_tune_res <- tune_grid(boost_wf,
                            resamples = airbnb_fold,
                            grid = boost_grid)
```

```{r, class.source = 'fold-hide'}
# save(boost_tune_res, boost_wf, boost_grid, boost_spec, file = "scripts/model_fitting/boost_model.rda")

load(file='scripts/model_fitting/boost_model.rda')
```

```{r}
autoplot(boost_tune_res)
```

```{r}
show_best(boost_tune_res, metric = "rsq")
show_best(boost_tune_res, metric = "rmse")
```

The R-squared value peaks at 0.612 around 64 trees and gradually declines afterwards and the RMSE is lowest then at 0.557 as well.

```{r, warning=FALSE,message=FALSE}
best_trees <- select_best(boost_tune_res)

boost_final <- finalize_workflow(boost_wf, best_trees)

boost_fit <- boost_final %>% 
  fit(airbnb_train)
```

### Random Forest Model

With the random forest, my mtry value has a frange from 1 to 8 as 8 is the number of predictors being used in the model, keeping that range for trees and min_n and levels at 4.

```{r, warning=FALSE,message=FALSE, eval=FALSE}
set.seed(2022)
rand_forest_spec <- rand_forest(mtry = tune(), 
                                trees = tune(), 
                                min_n = tune()) %>%
  set_engine("ranger", importance = 'impurity') %>%
  set_mode("regression")

# random forest workflow
rand_forest_wf <- workflow() %>%
  add_model(rand_forest_spec) %>%
  add_recipe(airbnb_recipe)

# define grid
rand_forest_grid <- grid_regular(mtry(range = c(1,8)),
                                      trees(range = c(1, 8)),
                                 min_n(range = c(1, 8)),  
                                       levels = 4)

# tuning grid for random forest model
rf_tune <- rand_forest_wf %>% 
  tune_grid(
    resamples = airbnb_fold, 
    grid = rand_forest_grid)
```

```{r, class.source = 'fold-hide', class.source = 'fold-hide'}
# save(rf_tune, rand_forest_wf, rand_forest_grid, rand_forest_spec, file = "scripts/model_fitting/rf_model.rda")
load('scripts/model_fitting/rf_model.rda')
```

```{r}
autoplot(rf_tune)
```

```{r}
show_best(rf_tune, metric = "rsq")

show_best(rf_tune, metric = "rmse")
```

We observe that with a higher number of randomly selected predictors used and higher number of trees, the greater the accuracy is as shown with the number of trees being 8 and mtry 5 having its R-squared value peaking at 0.585 and its RMSE value being lowest at 0.576

```{r, warning=FALSE,message=FALSE}
best_mtry <- select_best(rf_tune)

rf_final <- finalize_workflow(rand_forest_wf, best_mtry)

rf_fit <- rf_final %>% 
  fit(airbnb_train)
```

### K Nearest Neighbours Model

For Knn, the parameters take an argument of knn_spec and set levels to 8.

```{r, warning=FALSE,message=FALSE, eval=FALSE}
set.seed(2022)

knn_spec <- nearest_neighbor(
    neighbors = tune(),
    mode = "regression") %>% 
  set_engine("kknn")

# Knn workflow
knn_wf <- workflow() %>% 
  add_model(knn_spec) %>% 
  add_recipe(airbnb_recipe)

# define parameters for grid
knn_parameters <- parameters(knn_spec)

# create grid
knn_grid <- grid_regular(knn_parameters, levels = 8)

# tuning grid for knn model
knn_tune <- knn_wf %>% 
  tune_grid(
    resamples = airbnb_fold, 
    grid = knn_grid)
```

```{r warning=FALSE,message=FALSE, class.source = 'fold-hide'}
# save(knn_tune, knn_wf, knn_grid, knn_spec, file = "scripts/model_fitting/knn_model.rda")
load('scripts/model_fitting/knn_model.rda')
```

```{r}
autoplot(knn_tune)
```

```{r}
show_best(knn_tune, metric = "rsq")

show_best(knn_tune, metric = "rmse")
```

Here we observe that the greater the number of nearest neighbors, the better the accuracy as the R-squared value peaks at 0.546 around 15 neighbors and the RMSE is at 0.603.

```{r, warning=FALSE,message=FALSE}
best_knn <- select_best(knn_tune)

knn_final <- finalize_workflow(knn_wf, best_knn)

knn_fit <- knn_final %>% 
  fit(airbnb_train)
```

### Bagging

For Knn, the parameters take an argument of knn_spec and set levels to 4.
```{r, warning=FALSE,message=FALSE, eval=FALSE}
set.seed(2022)

bag_spec <-
  bag_tree(
    cost_complexity = tune(),
    tree_depth = tune(),
    min_n = tune()
  ) %>%
  set_engine("rpart", times = 10) %>%
  set_mode("regression")

# bagging workflow
bag_wf <-
  workflow() %>%
  add_recipe(airbnb_recipe) %>%
  add_model(bag_spec)

# defining parameters for bag_grid
bag_parameters <- parameters(bag_spec)

# creating grid
bag_grid <- grid_regular(bag_params, levels = 4)

# tuning grid for bagging model
bag_tune <- bag_wf %>% 
  tune_grid(
    # what will it fit the workflow to
    resamples = airbnb_fold, 
    # how does it complete the models in those workflows
    grid = bag_grid)
```

```{r, warning=FALSE,message=FALSE, class.source = 'fold-hide'}
# save(bag_tune, bag_wf, bag_grid, bag_spec, file = "scripts/model_fitting/bagging_model.rda")
load('scripts/model_fitting/bagging_model.rda')
```

```{r}
autoplot(bag_tune)
```

```{r}
show_best(bag_tune, metric = "rsq")

show_best(bag_tune, metric = "rmse")
```

We observe that the greater the tre depth, the better the accuracy is as shown with the tree depth of 15 with the R-squared value peaking at 0.592 and the RMSE being lowest at 0.571.

```{r, warning=FALSE,message=FALSE}
best_cost <- select_best(bag_tune)

bag_final <- finalize_workflow(bag_wf, best_cost)

bag_fit <- bag_final %>% 
  fit(airbnb_train)
```

## Model Selection & Performance

```{r, warning=FALSE,message=FALSE, class.source = 'fold-hide'}
boost_rsq <- augment(boost_fit, new_data = airbnb_test)%>%
  rsq(truth = price, estimate = .pred) 

boost_rmse <- augment(boost_fit, new_data = airbnb_test)%>%
  rmse(truth = price, estimate = .pred) 

rf_rsq <- augment(rf_fit, new_data = airbnb_test)%>%
  rsq(truth = price, estimate = .pred)

rf_rmse <- augment(rf_fit, new_data = airbnb_test)%>%
  rmse(truth = price, estimate = .pred)

knn_rsq <- augment(knn_fit, new_data = airbnb_test)%>%
  rsq(truth = price, estimate = .pred)

knn_rmse <- augment(knn_fit, new_data = airbnb_test)%>%
  rmse(truth = price, estimate = .pred)

bag_rsq <- augment(bag_fit, new_data = airbnb_test)%>%
  rsq(truth = price, estimate = .pred)

bag_rmse <- augment(bag_fit, new_data = airbnb_test)%>%
  rmse(truth = price, estimate = .pred)

model_names <- c("Boosting", "Random Forest", "K-Nearest Neighbors", "Bagging")

#
all_model_rsq <- c(boost_rsq$.estimate, rf_rsq$.estimate, knn_rsq$.estimate, bag_rsq$.estimate)
 
# 
all_model_rmse <- c(boost_rmse$.estimate, rf_rmse$.estimate, knn_rmse$.estimate, bag_rmse$.estimate)

all_model_results <- tibble(Model = model_names,
                             Rsq = all_model_rsq,
                            RMSE = all_model_rmse)
```

```{r}
all_model_results %>%
  arrange(desc(Rsq))
```

```{r, class.source = 'fold-hide'}
augment(boost_fit, new_data = airbnb_test) %>%
  ggplot(aes(price, .pred)) +
  geom_abline() +
  geom_point(alpha = 0.5)
```

Storing our accuracies in our table, we compare to find the our boosting model has the best accuracy with a R-squared value of 0.63, followed by random forest with 0.601, bagging with 0.599, and Knn with 0.566. With boosting specializing with fast gradient-boosting and high accuracy using the XGBoost library, it functions to match weak learners, which have poor predictive power, to a specified weighted subset of the dataset. Thus, our boosting model is effective with large data sets and applies tree algorithms that do not need normalized features with optimizing for regression. Observing the scatterplot with the true values compared to the predicted values, we notice that there is high variation that obviously comes with large dataset as the spread of prices is underfitted.

## Conclusion

While the accuracies of the predictive models were not ideal, we were able to compare the various applications of these machine learning techniques and see the full process taking place in order to build a model, tune it, and then fit a final selective model. With our boosting model having the best performance, I believe it showcases the model's advantage in improving its performance iteratively through the k-fold cross validation and gradually lowers bias and variance. Although as seen from the scatterplot, there is a case of underfitting present through our models. It was surprising to see that random forest did not have a better performance as I believed it would be better used for a focus as price prediction due to its application of multiple decision trees that results in a lesser chance of over-fitting and generally has a greater accuracy with lerger datasets. The model results in their RSQ were somewhat close in value from the lowet being 56% to the highest being 63%. If I were to do this again, I would include the "names" variable, which is the title the hosts manually input for their listings, to tokenize and see if certain words or phrases may correlate to the prices (e.g. "luxury" or "mansion" which may have more expensive values). Overall, 
